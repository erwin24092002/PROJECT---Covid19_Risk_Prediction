# -*- coding: utf-8 -*-
"""Kiet_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yk3V7P5jbaCIJAGg34TizylyGibb4c7e

### Name: Huynh Viet Tuan Kiet
### Student ID: 20521494
#**SUPPORT VECTOR MACHINE**

# **Setting up environment**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle
import time

from tqdm import tqdm
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""
    tools:
        1. C: Regularization parameter
        2. kernel: Specifies the kernel type to be used in the algorithm
        3. decision_function_shape: 
"""

def build_model(data_train, data_test, C, kernel, num):
    
    print("\nPending..........................................\n")

    # Setup data
    X_train, y_train = data_train.iloc[:,:-1], data_train.iloc[:,-1]
    X_test, y_test = data_test.iloc[:,:-1], data_test.iloc[:,-1]
    
    # Create model
    model = SVC(C=C, kernel=kernel)

    # Train model
    start = time.time()
    model.fit(X_train, y_train)
    end = time.time()

    # Save model
    filename = f"model_svm_{C}_{kernel}_all.sav"
    pickle.dump(model, open(filename, 'wb'))

    # Inference
    y_pred = model.predict(X_test)
    print(f"========= Sth: {num} - C={C} - kernel='{kernel}' ==========")
    print(f"Time to train: {end - start}s")
    print(f"Number of true predicted: {np.sum(y_pred == y_test)}/{len(y_test)}")
    print(f"Accuracy of C={C} and kernel='{kernel}': {accuracy_score(y_pred, y_test)}")
    print(f"Precision of C={C} and kernel='{kernel}': {precision_score(y_pred, y_test)}")
    print(f"Recall of C={C} and kernel='{kernel}' with average='None': {recall_score(y_pred, y_test, average=None)}")
    print(f"Recall of C={C} and kernel='{kernel}' with average='binary': {recall_score(y_pred, y_test, average='binary')}")
    print(f"Recall of C={C} and kernel='{kernel}' with average='micro': {recall_score(y_pred, y_test, average='micro')}")
    print(f"Recall of C={C} and kernel='{kernel}' with average='macro': {recall_score(y_pred, y_test, average='macro')}")
    print(f"Recall of C={C} and kernel='{kernel}' with average='weighted': {recall_score(y_pred, y_test, average='weighted')}")
    print(f"F1_score of C={C} and kernel='{kernel}' with average='None': {f1_score(y_pred, y_test, average=None)}")
    print(f"F1_score of C={C} and kernel='{kernel}' with average='binary': {f1_score(y_pred, y_test, average='binary')}")
    print(f"F1_score of C={C} and kernel='{kernel}' with average='micro': {f1_score(y_pred, y_test, average='micro')}")
    print(f"F1_score of C={C} and kernel='{kernel}' with average='macro': {f1_score(y_pred, y_test, average='macro')}")
    print(f"F1_score of C={C} and kernel='{kernel}' with average='weighted': {f1_score(y_pred, y_test, average='weighted')}")
    print("\n")
    with open(f"./svm_c{C}_{kernel}.txt", "a") as file_submit:
        file_submit.write(f"\n========= Sth: {num} - C={C} - kernel='{kernel}' ==========\n")
        file_submit.write(f"Time to train: {end - start}s\n")
        file_submit.write(f"Number of true predicted: {np.sum(y_pred == y_test)}/{len(y_test)}\n")
        file_submit.write(f"Accuracy of C={C} and kernel='{kernel}': {accuracy_score(y_pred, y_test)}\n")
        file_submit.write(f"Precision of C={C} and kernel='{kernel}': {precision_score(y_pred, y_test)}\n")
        file_submit.write(f"recall of C={C} and kernel='{kernel}' with average='None': {recall_score(y_pred, y_test, average=None)}\n")
        file_submit.write(f"recall of C={C} and kernel='{kernel}' with average='binary': {recall_score(y_pred, y_test, average='binary')}\n")
        file_submit.write(f"recall of C={C} and kernel='{kernel}' with average='micro': {recall_score(y_pred, y_test, average='micro')}\n")
        file_submit.write(f"recall of C={C} and kernel='{kernel}' with average='macro': {recall_score(y_pred, y_test, average='macro')}\n")
        file_submit.write(f"recall of C={C} and kernel='{kernel}' with average='weighted': {recall_score(y_pred, y_test, average='weighted')}\n")
        file_submit.write(f"F1_score of C={C} and kernel='{kernel}' with average='None': {f1_score(y_pred, y_test, average=None)}\n")
        file_submit.write(f"F1_score of C={C} and kernel='{kernel}' with average='binary': {f1_score(y_pred, y_test, average='binary')}\n")
        file_submit.write(f"F1_score of C={C} and kernel='{kernel}' with average='micro': {f1_score(y_pred, y_test, average='micro')}\n")
        file_submit.write(f"F1_score of C={C} and kernel='{kernel}' with average='macro': {f1_score(y_pred, y_test, average='macro')}\n")
        file_submit.write(f"F1_score of C={C} and kernel='{kernel}' with average='weighted': {f1_score(y_pred, y_test, average='weighted')}\n")

number_of_data = [1, 2, 3]
kernel_params = ["poly", "rbf", "sigmoid", "linear"]
c_params = [0.1, 1.0, 10.0, 100.0]

for num in tqdm(number_of_data):
    data_train = pd.read_csv(f'./lan{num}/train.csv')
    data_test = pd.read_csv(f'./lan{num}/test.csv')
    for kernel in tqdm(kernel_params):
        for c in tqdm(c_params):
            build_model(data_train, data_test, c, kernel, num)